{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 부산대학교 SW 융합교육원 K-train AIP 과정\n",
        "\n",
        "실습일자: 2025-07-14\n",
        "\n",
        "작성자: 김태연"
      ],
      "metadata": {
        "id": "4A0jI29W8e41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실습 문제: 최소-최대 정규화 (Min-Max Normalization)\n",
        "\n",
        "**설명**: 최소-최대 정규화는 데이터의 모든 값을 0과 1 사이의 범위로 조정하는 표준화 기법입니다. 이 방법은 데이터의 최솟값을 0으로, 최댓값을 1로 변환하여 모든 데이터 포인트가 이 범위 내에 비례적으로 위치하도록 만듭니다. 이번 실습의 목표는 주어진 숫자 리스트에 최소-최대 정규화 공식을 적용하는 Python 함수를 작성하는 것입니다.\n",
        "\n",
        "$$X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}}$$\n",
        "\n",
        "**요구사항**:\n",
        "\n",
        "  - 숫자 리스트를 인자로 받는 `min_max_normalize` 함수를 완성하세요.\n",
        "  - 함수 내에서 리스트의 최솟값(`min`)과 최댓값(`max`)을 찾으세요.\n",
        "  - 리스트의 각 숫자에 최소-최대 정규화 공식을 적용하여 새로운 리스트를 생성하고 반환하세요.\n",
        "  - 주어진 샘플 데이터로 함수를 테스트하고 결과를 출력하여 확인하세요.\n",
        "\n"
      ],
      "metadata": {
        "id": "A0f2p-xKAbT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def min_max_normalize(data: list[float]) -> list[float]:\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "sample_data = np.array([10, 20, 50, 60, 80, 100])\n",
        "normalized_data = min_max_normalize(sample_data)\n",
        "print(f\"Original Data: {sample_data}\")\n",
        "print(f\"Normalized Data: {normalized_data}\")"
      ],
      "metadata": {
        "id": "7z1gbGEcAaWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실습 문제: 표준화 (Z-score 정규화)\n",
        "\n",
        "**설명**: 표준화(Standardization), 또는 Z-score 정규화는 데이터의 분포를 평균이 0이고 표준편차가 1이 되도록 변환하는 방법입니다. 이 변환을 통해 서로 다른 단위나 스케일을 가진 데이터를 비교할 수 있게 됩니다. 이번 실습에서는 주어진 숫자 리스트를 Z-score 정규화 공식을 사용하여 표준화하는 Python 함수를 `Numpy` 라이브러리를 이용해 작성합니다.\n",
        "\n",
        "$$Z = \\frac{X - \\mu}{\\sigma}$$\n",
        "\n",
        "**요구사항**:\n",
        "\n",
        "  - `Numpy` 배열을 인자로 받는 `standardize` 함수를 완성하세요.\n",
        "  - 함수 내에서 `Numpy`를 사용하여 배열의 평균(`μ`)과 표준편차(`σ`)를 계산하세요.\n",
        "  - 배열의 각 요소에 Z-score 공식을 적용하여 새로운 배열을 생성하고 반환하세요.\n",
        "  - 주어진 샘플 데이터로 함수를 테스트하고, 변환된 데이터의 평균과 표준편차를 출력하여 결과가 0과 1에 가까운지 확인하세요.\n",
        "\n"
      ],
      "metadata": {
        "id": "X4M_e795BmAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "def standardize(data: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    주어진 Numpy 배열을 Z-score 정규화를 사용하여 표준화합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "sample_data = np.array([10, 20, 50, 60, 80, 100])\n",
        "standardized_data = standardize(sample_data)\n",
        "\n",
        "print(f\"Original Data: {sample_data}\")\n",
        "print(f\"Standardized Data: {standardized_data}\")\n",
        "print(f\"New Mean: {np.mean(standardized_data):.2f}\")\n",
        "print(f\"New Std Dev: {np.std(standardized_data):.2f}\")"
      ],
      "metadata": {
        "id": "IvaRhAsfBqXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실습 문제: 훈련, 검증, 테스트 데이터셋 분할\n",
        "\n",
        "**설명**:\n",
        "머신러닝 모델을 개발할 때, 전체 데이터셋을 **훈련(Training)**, **검증(Validation)**, **테스트(Test)** 세트로 나누는 것은 매우 중요합니다. 모델은 **훈련 세트**로 학습하고, **검증 세트**를 사용해 모델의 성능을 조정(튜닝)하며, 마지막으로 **테스트 세트**를 통해 학습 과정에 사용되지 않은 새로운 데이터에 대한 최종 성능을 공정하게 평가합니다. 이번 실습에서는 `Numpy`를 사용하여 주어진 데이터셋을 훈련, 검증, 테스트 세트로 분할하는 함수를 만듭니다.\n",
        "\n",
        "\n",
        "**요구사항**:\n",
        "\n",
        "  - 먼저 `np.random.shuffle()`을 사용해 전체 데이터셋의 순서를 무작위로 섞어 데이터가 편향되지 않도록 합니다.\n",
        "  - 데이터셋을 **8:1:1** 비율 (훈련 80%, 검증 10%, 테스트 10%)로 분할하세요. 전체 데이터의 개수를 기반으로 각 세트의 크기를 계산해야 합니다.\n",
        "  - 계산된 크기에 맞게 `Numpy` 배열 슬라이싱을 사용하여 `train_set`, `val_set`, `test_set`을 생성하고 반환하세요.\n",
        "  - 분할된 각 데이터셋의 크기(shape)를 출력하여 비율에 맞게 잘 나뉘었는지 확인합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "CQWi2o6Cx5BZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "def split_dataset(data: np.ndarray) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    주어진 데이터셋을 훈련, 검증, 테스트 세트로 8:1:1 비율로 분할합니다.\n",
        "\n",
        "    Args:\n",
        "        data: 원본 데이터셋 (Numpy 배열).\n",
        "\n",
        "    Returns:\n",
        "        훈련, 검증, 테스트 세트로 구성된 튜플.\n",
        "    \"\"\"\n",
        "    # 1. 데이터를 무작위로 섞습니다.\n",
        "    # 2. 데이터셋 크기를 계산합니다.\n",
        "    # 3. 데이터를 슬라이싱하여 세트를 나눕니다.\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "X = np.random.randn(150, 4)\n",
        "train, val, test = split_dataset(X)\n",
        "\n",
        "print(f\"Original data shape: {X.shape}\")\n",
        "print(f\"Training set shape: {train.shape}\")\n",
        "print(f\"Validation set shape: {val.shape}\")\n",
        "print(f\"Test set shape: {test.shape}\")"
      ],
      "metadata": {
        "id": "ZVf8ihZ_x-pW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}