{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Pandas DataFrame ì‹¤ìŠµ"
      ],
      "metadata": {
        "id": "_mdJEaGhgZ2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì‹¤ìŠµ ë¬¸ì œ: ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ê¸°ë³¸ íƒìƒ‰\n",
        "\n",
        "**ì„¤ëª…**: ë°ì´í„° ë¶„ì„ì˜ ì²« ë‹¨ê³„ëŠ” ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. Pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ì— ìˆëŠ” íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì…‹(CSV)ì„ DataFrameìœ¼ë¡œ ë¶ˆëŸ¬ì˜¨ í›„, `head()`, `info()`, `describe()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì˜ ìƒìœ„ 5ê°œ í–‰ê³¼ ì£¼ìš” ì •ë³´ ë° í†µê³„ëŸ‰ì„ í™•ì¸í•˜ëŠ” ì‹¤ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì„ í†µí•´ ë°ì´í„° ë¶„ì„ì˜ ê¸°ì´ˆë¥¼ ë‹¤ì§‘ë‹ˆë‹¤.\n",
        "\n",
        "**ìš”êµ¬ì‚¬í•­**:\n",
        "\n",
        "  - `url` ë³€ìˆ˜ì— ì €ì¥ëœ ì£¼ì†Œì˜ CSV íŒŒì¼ì„ `pandas.read_csv()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ `titanic_df` ë³€ìˆ˜ì— ì €ì¥í•˜ì„¸ìš”.\n",
        "  - `titanic_df`ì˜ ìƒìœ„ 5ê°œ í–‰ì„ `head()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í™”ë©´ì— ì¶œë ¥í•˜ì„¸ìš”.\n",
        "  - `titanic_df`ì˜ ë°ì´í„°ì— ëŒ€í•œ ì£¼ìš” ì •ë³´ë¥¼ `info()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í™”ë©´ì— ì¶œë ¥í•˜ì„¸ìš”.\n",
        "  - `titanic_df`ì˜ ìˆ«ìí˜• ë°ì´í„°ì— ëŒ€í•œ ì£¼ìš” í†µê³„ ì •ë³´ë¥¼ `describe()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í™”ë©´ì— ì¶œë ¥í•˜ì„¸ìš”.\n",
        "\n"
      ],
      "metadata": {
        "id": "QdaLLLSDr3AF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in7zgkP1rxIp"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "def load_and_explore_titanic():\n",
        "    \"\"\"\n",
        "    íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì™€ ìƒìœ„ 5ê°œ í–‰ê³¼ í†µê³„ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    url = 'https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/train.csv'\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "load_and_explore_titanic()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì‹¤ìŠµ ë¬¸ì œ: ëˆ„ë½ëœ ë‚˜ì´(Age) ë°ì´í„° ì±„ìš°ê¸°\n",
        "\n",
        "**ì„¤ëª…**: ì‹¤ì œ ë°ì´í„°ì—ëŠ” ì¢…ì¢… ê°’ì´ ëˆ„ë½ëœ ê²½ìš°ê°€ ìˆìœ¼ë©°, ì´ë¥¼ 'ê²°ì¸¡ì¹˜'ë¼ê³  í•©ë‹ˆë‹¤. ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ê²°ì¸¡ì¹˜ë¥¼ ì ì ˆíˆ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì…‹ì˜ 'Age' ì—´ì— ìˆëŠ” ê²°ì¸¡ì¹˜ë¥¼ í™•ì¸í•˜ê³ , ì „ì²´ ìŠ¹ê°ì˜ í‰ê·  ë‚˜ì´ë¡œ ì±„ìš°ëŠ” ë°©ë²•ì„ `isna()`, `mean()`, `fillna()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "\n",
        "$$\\text{í‰ê·  ë‚˜ì´} = \\frac{\\sum_{i=1}^{n} \\text{Age}_i}{n}$$\n",
        "\n",
        "**ìš”êµ¬ì‚¬í•­**:\n",
        "\n",
        "  - `titanic_df`ì˜ 'Age' ì—´ì— ê²°ì¸¡ì¹˜ê°€ ëª‡ ê°œ ìˆëŠ”ì§€ `isna().sum()`ì„ ì‚¬ìš©í•˜ì—¬ í™•ì¸í•˜ê³  ì¶œë ¥í•˜ì„¸ìš”.\n",
        "  - 'Age' ì—´ì˜ ì „ì²´ í‰ê·  ë‚˜ì´ë¥¼ `mean()` í•¨ìˆ˜ë¡œ ê³„ì‚°í•˜ì—¬ `mean_age` ë³€ìˆ˜ì— ì €ì¥í•˜ì„¸ìš”.\n",
        "  - `fillna()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ 'Age' ì—´ì˜ ê²°ì¸¡ì¹˜(NaN)ë¥¼ `mean_age` ê°’ìœ¼ë¡œ ì±„ìš°ê³ , `inplace=True` ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ DataFrameì— ë°”ë¡œ ì ìš©í•˜ì„¸ìš”.\n",
        "  - ì²˜ë¦¬ í›„ 'Age' ì—´ì— ê²°ì¸¡ì¹˜ê°€ ì—†ëŠ”ì§€ ë‹¤ì‹œ `isna().sum()`ìœ¼ë¡œ í™•ì¸í•˜ì—¬ ì¶œë ¥í•˜ì„¸ìš”.\n",
        "\n"
      ],
      "metadata": {
        "id": "vM_3BwY3uViT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def impute_age(titanic_df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì…‹ì˜ 'Age' ì—´ì— ìˆëŠ” ê²°ì¸¡ì¹˜ë¥¼ í‰ê·  ë‚˜ì´ë¡œ ì±„ì›ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "\n",
        "    # ìš”êµ¬ì‚¬í•­ 1: ì²˜ë¦¬ ì „ 'Age' ì—´ì˜ ê²°ì¸¡ì¹˜ ê°œìˆ˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "    # ìš”êµ¬ì‚¬í•­ 2: 'Age' ì—´ì˜ í‰ê· ê°’ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "    # ìš”êµ¬ì‚¬í•­ 3: 'Age' ì—´ì˜ ê²°ì¸¡ì¹˜ë¥¼ í‰ê· ê°’ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤. (inplace=True ì‚¬ìš©)\n",
        "    # ìš”êµ¬ì‚¬í•­ 4: ì²˜ë¦¬ í›„ 'Age' ì—´ì˜ ê²°ì¸¡ì¹˜ ê°œìˆ˜ë¥¼ ë‹¤ì‹œ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "    # ìµœì¢… í™•ì¸\n",
        "    print(\"\\nê²°ì¸¡ì¹˜ ì²˜ë¦¬ í›„ info:\")\n",
        "\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/train.csv'\n",
        "titanic_df = pd.read_csv(url)\n",
        "\n",
        "impute_age(titanic_df)\n"
      ],
      "metadata": {
        "id": "iDtEvxo0uehU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì‹¤ìŠµ ë¬¸ì œ: ì¡°ê±´ë¶€ ë°ì´í„° ì„ íƒ ë° í•„í„°ë§\n",
        "\n",
        "**ì„¤ëª…**: DataFrameì—ì„œ ì›í•˜ëŠ” ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” ê²ƒì€ ë°ì´í„° ë¶„ì„ì˜ í•µì‹¬ì…ë‹ˆë‹¤. ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì…‹ì—ì„œ **ìƒì¡´í•œ ìŠ¹ê°**ë“¤ì˜ ë°ì´í„°ë§Œ í•„í„°ë§í•˜ê³ , ê·¸ì¤‘ íŠ¹ì • ì—´(ì´ë¦„, ë‚˜ì´, ì„±ë³„)ë§Œ ì„ íƒí•˜ëŠ” ë°©ë²•ì„ ì—°ìŠµí•©ë‹ˆë‹¤. **Boolean Masking**ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” í–‰ì„ ì¶”ì¶œí•˜ê³ , ì—´ ì´ë¦„ì„ ì´ìš©í•˜ì—¬ ì›í•˜ëŠ” ë°ì´í„°ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.\n",
        "\n",
        "**ìš”êµ¬ì‚¬í•­**:\n",
        "\n",
        "  - `titanic_df` DataFrameì—ì„œ 'Survived' ì—´ì˜ ê°’ì´ `1`ì¸ (ìƒì¡´ì) í–‰ë“¤ë§Œ ì¶”ì¶œí•˜ì—¬ `survivors_df` ë³€ìˆ˜ì— ì €ì¥í•˜ì„¸ìš”.\n",
        "  - `survivors_df`ì—ì„œ 'Name', 'Age', 'Sex' ì„¸ ê°œì˜ ì—´ë§Œ ì„ íƒí•˜ì—¬ `survivor_details` ë³€ìˆ˜ì— ì €ì¥í•˜ì„¸ìš”.\n",
        "  - `survivor_details` DataFrameì˜ ì²« 5ê°œ í–‰ì„ `head()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶œë ¥í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n",
        "\n"
      ],
      "metadata": {
        "id": "I5nD4WC_sa9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "def filter_survivors(titanic_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì…‹ì—ì„œ ìƒì¡´í•œ ìŠ¹ê°ì˜ ì´ë¦„, ë‚˜ì´, ì„±ë³„ ì •ë³´ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤.\n",
        "\n",
        "    Args:\n",
        "        titanic_df (pd.DataFrame): ì›ë³¸ íƒ€ì´íƒ€ë‹‰ ë°ì´í„° í”„ë ˆì„\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: í•„í„°ë§ëœ ë°ì´í„° í”„ë ˆì„\n",
        "    \"\"\"\n",
        "\n",
        "    # ìš”êµ¬ì‚¬í•­ 1: 'Survived' ì—´ì´ 1ì¸ í–‰ë§Œ í•„í„°ë§í•˜ì„¸ìš”.\n",
        "    # ìš”êµ¬ì‚¬í•­ 2: 'Name', 'Age', 'Sex' ì—´ì„ ì„ íƒí•˜ì„¸ìš”.\n",
        "    # ìš”êµ¬ì‚¬í•­ 3: ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì—¬ í™•ì¸í•˜ì„¸ìš”.\n",
        "    print(\"--- ìƒì¡´ì ìƒì„¸ ì •ë³´ (ìƒìœ„ 5ëª…) ---\")\n",
        "\n",
        "    return survivor_details\n",
        "\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/train.csv'\n",
        "titanic_df = pd.read_csv(url)\n",
        "survivor_info = filter_survivors(titanic_df)\n"
      ],
      "metadata": {
        "id": "0EqYVhwtsqc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì‹¤ìŠµ ë¬¸ì œ: ìµœê³  ìš”ê¸ˆ ìŠ¹ê° ì°¾ê¸° ë° ìš”ê¸ˆ ë‹¨ìœ„ ë³€í™˜\n",
        "\n",
        "**ì„¤ëª…**: ë°ì´í„°ë¥¼ ì¡°ì‘í•˜ê³  ìƒˆë¡œìš´ ì •ë³´ë¥¼ íŒŒìƒì‹œí‚¤ëŠ” ê²ƒì€ ì¤‘ìš”í•œ ë¶„ì„ ê¸°ìˆ ì…ë‹ˆë‹¤. ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” íƒ€ì´íƒ€ë‹‰í˜¸ì— ê°€ì¥ ë§ì€ ìš”ê¸ˆì„ ë‚¸ ìŠ¹ê° 5ëª…ì„ ì°¾ê³ , ë‹¹ì‹œ ìš”ê¸ˆ(ì˜êµ­ íŒŒìš´ë“œ)ì„ í˜„ì¬ì˜ ì›í™” ê°€ì¹˜ë¡œ ë³€í™˜í•˜ëŠ” ì‘ì—…ì„ í•©ë‹ˆë‹¤. `nlargest()`ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒìœ„ ë°ì´í„°ë¥¼ ì°¾ê³ , ìƒˆë¡œìš´ ì—´ì„ ì¶”ê°€í•˜ì—¬ ê³„ì‚° ê²°ê³¼ë¥¼ ì €ì¥í•œ í›„, `sort_values()`ë¡œ ì •ë ¬í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "$$\\text{Fare\\_KRW} = \\text{Fare} \\times 1800$$\n",
        "\n",
        "**ìš”êµ¬ì‚¬í•­**:\n",
        "\n",
        "  - 'Fare' ì—´ì„ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ë†’ì€ ìš”ê¸ˆì„ ë‚¸ 5ëª…ì˜ ë°ì´í„°ë¥¼ `nlargest()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ `top_fare_df` ë³€ìˆ˜ì— ì €ì¥í•˜ì„¸ìš”.\n",
        "  - `top_fare_df`ì— 'Fare\\_KRW'ë¼ëŠ” ìƒˆë¡œìš´ ì—´ì„ ì¶”ê°€í•˜ì„¸ìš”. ì´ ì—´ì˜ ê°’ì€ ê¸°ì¡´ 'Fare' ì—´ ê°’ì— í™˜ìœ¨(`1800`)ì„ ê³±í•œ ê²°ê³¼ì…ë‹ˆë‹¤.\n",
        "  - 'Fare' ì—´ì„ ê¸°ì¤€ìœ¼ë¡œ **ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬**í•˜ê³ , 'Name', 'Pclass', 'Fare', 'Fare\\_KRW' ì—´ë§Œ ì„ íƒí•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.\n"
      ],
      "metadata": {
        "id": "G-tMPkuwtB8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "def find_and_convert_top_fares(titanic_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    ê°€ì¥ ë†’ì€ ìš”ê¸ˆì„ ë‚¸ ìŠ¹ê° 5ëª…ì„ ì°¾ê³ , ìš”ê¸ˆì„ ì›í™”ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    # í™˜ìœ¨ ì •ì˜\n",
        "    exchange_rate = 1800\n",
        "\n",
        "    # ìš”êµ¬ì‚¬í•­ 1: 'Fare'ê°€ ê°€ì¥ ë†’ì€ ìƒìœ„ 5ëª…ì˜ ë°ì´í„°ë¥¼ ì°¾ìœ¼ì„¸ìš”.\n",
        "    # ìš”êµ¬ì‚¬í•­ 2: 'Fare_KRW' ì—´ì„ ì¶”ê°€í•˜ê³  í™˜ì‚°ëœ ìš”ê¸ˆì„ ì €ì¥í•˜ì„¸ìš”.\n",
        "    # ìš”êµ¬ì‚¬í•­ 3: 'Fare' ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ í›„, ì§€ì •ëœ ì—´ë§Œ ì„ íƒí•˜ì—¬ ì¶œë ¥í•˜ì„¸ìš”.\n",
        "    print(\"--- ìµœê³  ìš”ê¸ˆ ìŠ¹ê° Top 5 (ìš”ê¸ˆ ì›í™” ë³€í™˜) ---\")\n",
        "\n",
        "    return final_df\n",
        "\n",
        "\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/train.csv'\n",
        "titanic_df = pd.read_csv(url)\n",
        "top_fare_info = find_and_convert_top_fares(titanic_df)\n"
      ],
      "metadata": {
        "id": "WdfdAjfktYCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì‹¤ìŠµ ë¬¸ì œ: ê°ì‹¤ ë“±ê¸‰ë³„ ìƒì¡´ìœ¨ ë° í‰ê·  ë‚˜ì´ ë¶„ì„\n",
        "\n",
        "**ì„¤ëª…**: ë°ì´í„°ë¥¼ íŠ¹ì • ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì§‘ê³„í•˜ëŠ” ê²ƒì€ ë°ì´í„°ì˜ ìˆ¨ê²¨ì§„ íŒ¨í„´ì„ ë°œê²¬í•˜ëŠ” ê°•ë ¥í•œ ë°©ë²•ì…ë‹ˆë‹¤. ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” `groupby()`ì™€ `agg()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ íƒ€ì´íƒ€ë‹‰í˜¸ì˜ ê°ì‹¤ ë“±ê¸‰(`Pclass`)ë³„ë¡œ ìŠ¹ê°ë“¤ì˜ í‰ê·  ìƒì¡´ìœ¨ê³¼ í‰ê·  ë‚˜ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì„ í†µí•´ ê° ê°ì‹¤ ë“±ê¸‰ì´ ìƒì¡´ì— ë¯¸ì¹œ ì˜í–¥ì„ í†µê³„ì ìœ¼ë¡œ ë¶„ì„í•´ ë´…ë‹ˆë‹¤. ìƒì¡´ ì—¬ë¶€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” 'Survived' ì—´(ì‚¬ë§ 0, ìƒì¡´ 1)ì˜ í‰ê· ê°’ì€ ê³§ ìƒì¡´ìœ¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "$$\\text{Survival Rate} = \\frac{\\sum(\\text{Survived})}{\\text{count}(\\text{Passengers})} = \\text{mean}(\\text{Survived})$$\n",
        "\n",
        "**ìš”êµ¬ì‚¬í•­**:\n",
        "\n",
        "  - `titanic_df` DataFrameì„ 'Pclass' ì—´ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì„¸ìš”.\n",
        "  - ê·¸ë£¹í™”ëœ ê°ì²´ì— `agg()` í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ ê° ê°ì‹¤ ë“±ê¸‰(`Pclass`)ë³„ 'Survived' ì—´ì˜ í‰ê· (ìƒì¡´ìœ¨)ê³¼ 'Age' ì—´ì˜ í‰ê· (í‰ê·  ë‚˜ì´)ì„ ë™ì‹œì— ê³„ì‚°í•˜ì„¸ìš”.\n",
        "  - ê³„ì‚°ëœ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì—¬ í™•ì¸í•˜ì„¸ìš”. ê²°ê³¼ëŠ” ê° ê°ì‹¤ ë“±ê¸‰ì„ ì¸ë±ìŠ¤ë¡œ ê°–ê³ , 'Survived'ì™€ 'Age'ë¥¼ ì—´ë¡œ ê°–ëŠ” DataFrameì´ ë©ë‹ˆë‹¤.\n",
        "\n"
      ],
      "metadata": {
        "id": "DVuXnGy-t05a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def analyze_by_class(titanic_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    ê°ì‹¤ ë“±ê¸‰(Pclass)ë³„ í‰ê·  ìƒì¡´ìœ¨ê³¼ í‰ê·  ë‚˜ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "\n",
        "    # ìš”êµ¬ì‚¬í•­ 1 & 2: 'Pclass'ë¡œ ê·¸ë£¹í™”í•˜ê³  'Survived'ì™€ 'Age'ì˜ í‰ê· ì„ ê³„ì‚°í•˜ì„¸ìš”.\n",
        "    # 'Survived'ì˜ í‰ê· ì€ ìƒì¡´ìœ¨ì„, 'Age'ì˜ í‰ê· ì€ í‰ê·  ë‚˜ì´ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
        "    # ìš”êµ¬ì‚¬í•­ 3: ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì—¬ í™•ì¸í•˜ì„¸ìš”.\n",
        "    print(\"--- ê°ì‹¤ ë“±ê¸‰ë³„ ìƒì¡´ìœ¨ ë° í‰ê·  ë‚˜ì´ ---\")\n",
        "\n",
        "    return analysis_df\n",
        "\n",
        "\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/train.csv'\n",
        "titanic_df = pd.read_csv(url)\n",
        "\n",
        "class_analysis = analyze_by_class(titanic_df)\n"
      ],
      "metadata": {
        "id": "8ps3VNGKt7cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì‹¤ìŠµ ë¬¸ì œ: ë‚˜ì´ëŒ€ ë° ì„±ë³„ ë°ì´í„° ë³€í™˜\n",
        "\n",
        "**ì„¤ëª…**: ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ ìˆ«ìí˜• ë°ì´í„°ë¥¼ ì£¼ë¡œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—, ì¢…ì¢… ê¸°ì¡´ ë°ì´í„°ë¥¼ ë¶„ì„ ëª©ì ì— ë§ê²Œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” 'Age' ì—´ì„ ì´ìš©í•˜ì—¬ 'Age\\_Group' (ë‚˜ì´ëŒ€)ì´ë¼ëŠ” ìƒˆë¡œìš´ ë²”ì£¼í˜• ì—´ì„ ë§Œë“¤ê³ , 'Sex' ì—´ì˜ ë¬¸ìì—´ ë°ì´í„°ë¥¼ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. `apply` ë©”ì†Œë“œì™€ `lambda` í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "\n",
        "**ìš”êµ¬ì‚¬í•­**:\n",
        "\n",
        "  - ë‚˜ì´ë¥¼ ì…ë ¥ë°›ì•„ ë‚˜ì´ëŒ€ ë¬¸ìì—´('Child', 'Young', 'Adult', 'Senior')ì„ ë°˜í™˜í•˜ëŠ” `get_age_group` í•¨ìˆ˜ê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤.\n",
        "  - `apply`ì™€ `lambda` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ `titanic_df['Age']`ì˜ ê° ê°’ì— `get_age_group` í•¨ìˆ˜ë¥¼ ì ìš©í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ 'Age\\_Group'ì´ë¼ëŠ” ìƒˆ ì—´ì— ì €ì¥í•˜ì„¸ìš”.\n",
        "  - `apply`ì™€ `lambda` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ 'Sex' ì—´ì˜ ê°’ì„ ë³€í™˜í•˜ì„¸ìš”. 'male'ì€ `0`ìœ¼ë¡œ, 'female'ì€ `1`ë¡œ ë³€í™˜í•˜ì—¬ ê¸°ì¡´ 'Sex' ì—´ì„ ë®ì–´ì“°ì„¸ìš”.\n",
        "  - ë³€í™˜ ì‘ì—…ì´ ì™„ë£Œëœ í›„, 'Age', 'Age\\_Group', 'Sex' ì„¸ ì—´ì˜ ìƒìœ„ 5ê°œ í–‰ì„ ì¶œë ¥í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n",
        "\n"
      ],
      "metadata": {
        "id": "3MepVCjruvjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "def get_age_group(age: float) -> str:\n",
        "    \"\"\"ë‚˜ì´ë¥¼ ë°›ì•„ ë‚˜ì´ëŒ€ ë¬¸ìì—´ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
        "    if age <= 13:\n",
        "        return 'Child'\n",
        "    elif age <= 25:\n",
        "        return 'Young'\n",
        "    elif age <= 64:\n",
        "        return 'Adult'\n",
        "    else:\n",
        "        return 'Senior'\n",
        "\n",
        "def transform_data(titanic_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    'Age' ì—´ë¡œ 'Age_Group' ì—´ì„ ìƒì„±í•˜ê³  'Sex' ì—´ì„ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ì„ í–‰ ì‘ì—…)\n",
        "    # ìš”êµ¬ì‚¬í•­ 1 & 2: applyì™€ lambdaë¥¼ ì‚¬ìš©í•˜ì—¬ 'Age_Group' ì—´ì„ ìƒì„±í•˜ì„¸ìš”.\n",
        "    # ìš”êµ¬ì‚¬í•­ 3: applyì™€ lambdaë¥¼ ì‚¬ìš©í•˜ì—¬ 'Sex' ì—´ì„ 0ê³¼ 1ë¡œ ë³€í™˜í•˜ì„¸ìš”.\n",
        "    # ìš”êµ¬ì‚¬í•­ 4: ë³€í™˜ëœ ê²°ê³¼ì˜ ì¼ë¶€ë¥¼ ì¶œë ¥í•˜ì—¬ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "    print(\"--- ë°ì´í„° ë³€í™˜ ê²°ê³¼ (ìƒìœ„ 5í–‰) ---\")\n",
        "\n",
        "    return titanic_df\n",
        "\n",
        "\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/train.csv'\n",
        "titanic_df = pd.read_csv(url)\n",
        "\n",
        "transformed_df = transform_data(titanic_df)"
      ],
      "metadata": {
        "id": "oDAJpZHZu3tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Pandas groupby ì‹¤ìŠµ"
      ],
      "metadata": {
        "id": "cJhIsIpFCWcG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ì‹¤ìŠµ ë¬¸ì œ: í’ˆì¢…ë³„ í‰ê·  ê³„ì‚°í•˜ê¸° (`agg`)\n",
        "\n",
        "**ì„¤ëª…**: `groupby()`ì™€ `mean()` (ë˜ëŠ” `agg('mean')`)ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì„ íŠ¹ì • ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ê³ , ê° ê·¸ë£¹ì˜ í†µê³„ì  ìš”ì•½(ì—¬ê¸°ì„œëŠ” í‰ê· )ì„ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì„ ì—°ìŠµí•©ë‹ˆë‹¤. `iris` DataFrameì˜ ê° í’ˆì¢…(`species`)ë³„ë¡œ ëª¨ë“  ìˆ˜ì¹˜ íŠ¹ì„±(ê½ƒë°›ì¹¨ ë° ê½ƒìì˜ ê¸¸ì´ì™€ ë„ˆë¹„)ì˜ í‰ê· ê°’ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì™„ì„±í•´ ë³´ì„¸ìš”.\n",
        "\n",
        "**ìš”êµ¬ì‚¬í•­**:\n",
        "\n",
        "  - `calculate_species_mean` í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”.\n",
        "  - í•¨ìˆ˜ ë‚´ì—ì„œ ì£¼ì–´ì§„ `df` DataFrameì„ `species` ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì„¸ìš”.\n",
        "  - ê·¸ë£¹í™”ëœ ê°ì²´ì— `mean()` í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ í’ˆì¢…ë³„ í‰ê· ì„ ê³„ì‚°í•˜ê³  ë°˜í™˜í•˜ì„¸ìš”.\n",
        "\n"
      ],
      "metadata": {
        "id": "hI19sMjzB2I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "def calculate_species_mean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    iris DataFrameì„ í’ˆì¢…(species)ë³„ë¡œ ê·¸ë£¹í™”í•˜ê³  ê° íŠ¹ì„±ì˜ í‰ê· ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "\n",
        "    ë§¤ê°œë³€ìˆ˜:\n",
        "        df: 'species' ì»¬ëŸ¼ì„ í¬í•¨í•˜ëŠ” ì…ë ¥ iris DataFrameì…ë‹ˆë‹¤.\n",
        "\n",
        "    ë°˜í™˜ê°’:\n",
        "        ê° í’ˆì¢…ë³„ë¡œ ê° íŠ¹ì„±ì˜ í‰ê· ì„ ë‹´ì€ DataFrameì…ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
        "\n",
        "species_mean = calculate_species_mean(df)\n",
        "species_mean\n"
      ],
      "metadata": {
        "id": "aji5P_F4CSQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ì‹¤ìŠµ ë¬¸ì œ: íŠ¹ì • ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê·¸ë£¹ ì°¾ê¸° (`filter`)\n",
        "\n",
        "**ì„¤ëª…**: `filter()`ëŠ” ê·¸ë£¹ ì „ì²´ì˜ íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ëŠ” ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤. ğŸ•µï¸â€â™€ï¸ SQLì˜ `HAVING` ì ˆê³¼ ìœ ì‚¬í•˜ê²Œ, ê·¸ë£¹ë³„ ì§‘ê³„ ê²°ê³¼ê°€ íŠ¹ì • ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê·¸ë£¹ì˜ ëª¨ë“  í–‰ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” í’ˆì¢…ë³„ í‰ê·  `petal length (cm)`ê°€ 4.0cm ì´ìƒì¸ í’ˆì¢… ê·¸ë£¹ ì „ì²´ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ë¥¼ ì™„ì„±í•´ ë³´ì„¸ìš”.\n",
        "\n",
        "**ìš”êµ¬ì‚¬í•­**:\n",
        "\n",
        "  * `filter_by_petal_length` í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”.\n",
        "  * í•¨ìˆ˜ ë‚´ì—ì„œ `species` ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•œ í›„, `filter()`ì™€ `lambda` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n",
        "  * ê·¸ë£¹ë³„ 'petal length (cm)'ì˜ í‰ê· ê°’ì´ 4.0 ì´ìƒì¸ ê·¸ë£¹ë§Œ ë‚¨ë„ë¡ í•„í„°ë§í•˜ì—¬ ë°˜í™˜í•˜ì„¸ìš”.\n",
        "\n"
      ],
      "metadata": {
        "id": "nDy15CHdCwHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "def filter_by_petal_length(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    iris DataFrameì„ í’ˆì¢…ë³„ë¡œ ê·¸ë£¹í™”í•˜ê³ , íŠ¹ì • ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê·¸ë£¹ì„ í•„í„°ë§í•©ë‹ˆë‹¤.\n",
        "\n",
        "    ë§¤ê°œë³€ìˆ˜:\n",
        "        df: 'species'ì™€ 'petal length (cm)' ì»¬ëŸ¼ì„ í¬í•¨í•˜ëŠ” iris DataFrameì…ë‹ˆë‹¤.\n",
        "\n",
        "    ë°˜í™˜ê°’:\n",
        "        'petal length (cm)'ì˜ ê·¸ë£¹ í‰ê· ì´ 4.0 ì´ìƒì¸ í’ˆì¢… ê·¸ë£¹ì˜ ë°ì´í„°ë§Œ í¬í•¨í•˜ëŠ” DataFrameì…ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
        "\n",
        "filtered_df = filter_by_petal_length(df)\n",
        "print(\"í•„í„°ë§ í›„ ë‚¨ì€ í’ˆì¢…:\", filtered_df['species'].unique())\n",
        "print(\"í•„í„°ë§ëœ ë°ì´í„°ì˜ í–‰ ê°œìˆ˜:\", len(filtered_df))\n"
      ],
      "metadata": {
        "id": "TDyx59BmC4M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ì‹¤ìŠµ ë¬¸ì œ: ê·¸ë£¹ í‰ê· ê³¼ì˜ ì°¨ì´ ê³„ì‚°í•˜ê¸° (`transform`)\n",
        "\n",
        "**ì„¤ëª…**: `transform()`ì€ ê·¸ë£¹ë³„ë¡œ ê³„ì‚°í•œ ê°’ì„ ì›ë³¸ ë°ì´í„°ì˜ ê° í–‰ì— ë‹¤ì‹œ ë§¤í•‘í•´ì£¼ëŠ” ìœ ìš©í•œ ê¸°ëŠ¥ì…ë‹ˆë‹¤. ğŸ“ˆ ì´ë¥¼ í†µí•´ ê° ë°ì´í„° í¬ì¸íŠ¸ê°€ ì†í•œ ê·¸ë£¹ì˜ í†µê³„ì¹˜ì™€ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ ì‰½ê²Œ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° ë¶“ê½ƒ ë°ì´í„°ì˜ `petal width (cm)`ê°€ ìì‹ ì´ ì†í•œ í’ˆì¢…ì˜ í‰ê·  `petal width (cm)`ì™€ ì–¼ë§ˆë‚˜ ì°¨ì´ ë‚˜ëŠ”ì§€ë¥¼ ê³„ì‚°í•˜ì—¬ ìƒˆ ì»¬ëŸ¼ì— ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì™„ì„±í•´ ë³´ì„¸ìš”.\n",
        "\n",
        "**ìš”êµ¬ì‚¬í•­**:\n",
        "\n",
        "  * `calculate_deviation_from_mean` í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”.\n",
        "  * í•¨ìˆ˜ ë‚´ì—ì„œ `species` ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ê³ , `petal width (cm)` ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”.\n",
        "  * `transform()`ê³¼ `lambda` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ë°ì´í„°ì˜ ê°’ì—ì„œ ê·¸ë£¹ë³„ í‰ê· ì„ ëº€ 'í¸ì°¨(deviation)'ë¥¼ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•˜ì„¸ìš”.\n",
        "\n"
      ],
      "metadata": {
        "id": "WQp18tVPDE4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "def calculate_deviation_from_mean(df: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"\n",
        "    ê° ë°ì´í„°ê°€ ì†í•œ í’ˆì¢…ì˜ 'petal width (cm)' í‰ê· ê°’ê³¼ì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "\n",
        "    ë§¤ê°œë³€ìˆ˜:\n",
        "        df: 'species'ì™€ 'petal width (cm)' ì»¬ëŸ¼ì„ í¬í•¨í•˜ëŠ” iris DataFrameì…ë‹ˆë‹¤.\n",
        "\n",
        "    ë°˜í™˜ê°’:\n",
        "        ê° ë°ì´í„°ì˜ 'petal width (cm)'ì™€ í•´ë‹¹ í’ˆì¢…ì˜ í‰ê·  'petal width (cm)' ì‚¬ì´ì˜ í¸ì°¨ë¥¼ ë‹´ì€ Seriesì…ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
        "\n",
        "df['petal_width_deviation'] = calculate_deviation_from_mean(df)\n",
        "df[['species', 'petal width (cm)', 'petal_width_deviation']].head()"
      ],
      "metadata": {
        "id": "d33APdHhDJZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ì‹¤ìŠµ ë¬¸ì œ: ê° ê·¸ë£¹ì—ì„œ íŠ¹ì • ì¡°ê±´ì˜ ë°ì´í„° ì¶”ì¶œí•˜ê¸° (`apply`)\n",
        "\n",
        "**ì„¤ëª…**: `apply()`ëŠ” `agg`, `filter`, `transform`ìœ¼ë¡œ í•´ê²°í•˜ê¸° ì–´ë ¤ìš´ ë³µì¡í•œ ë§ì¶¤í˜• í•¨ìˆ˜ë¥¼ ê° ê·¸ë£¹ì— ì ìš©í•  ë•Œ ì‚¬ìš©í•˜ëŠ” \"ë§ŒëŠ¥ ì¹˜íŠ¸í‚¤\"ì…ë‹ˆë‹¤. ğŸƒ ì—¬ê¸°ì„œëŠ” ê° í’ˆì¢… ê·¸ë£¹ ë‚´ì—ì„œ `petal width (cm)`ê°€ \\*\\*ê°€ì¥ ì‘ì€ ë°ì´í„°(ìµœì†Œê°’)\\*\\*ë¥¼ í•˜ë‚˜ì”© ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ë¥¼ `apply`ë¥¼ ì´ìš©í•´ ì™„ì„±í•´ ë´…ë‹ˆë‹¤.\n",
        "\n",
        "**ìš”êµ¬ì‚¬í•­**:\n",
        "\n",
        "  * `get_smallest_petal_width_row` í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì—¬, ì…ë ¥ëœ ê·¸ë£¹(`group`)ì—ì„œ 'petal width (cm)' ê°’ì´ ê°€ì¥ ì‘ì€ í–‰ì„ ë°˜í™˜í•˜ë„ë¡ í•˜ì„¸ìš”. (`nsmallest()` í•¨ìˆ˜ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.)\n",
        "  * `find_smallest_in_group` í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”.\n",
        "  * í•¨ìˆ˜ ë‚´ì—ì„œ `species`ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ê³ , `apply()`ë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ„ì—ì„œ ì •ì˜í•œ í—¬í¼ í•¨ìˆ˜ë¥¼ ê° ê·¸ë£¹ì— ì ìš©í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì„¸ìš”."
      ],
      "metadata": {
        "id": "9tBzRb_JDeo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "def get_smallest_petal_width_row(group: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    ì£¼ì–´ì§„ ê·¸ë£¹(DataFrame)ì—ì„œ 'petal width (cm)'ê°€ ê°€ì¥ ì‘ì€ í–‰ì„ ì°¾ìŠµë‹ˆë‹¤.\n",
        "\n",
        "    ë§¤ê°œë³€ìˆ˜:\n",
        "        group: ë‹¨ì¼ í’ˆì¢…ìœ¼ë¡œ êµ¬ì„±ëœ DataFrame ê·¸ë£¹ì…ë‹ˆë‹¤.\n",
        "\n",
        "    ë°˜í™˜ê°’:\n",
        "        'petal width (cm)'ê°€ ê°€ì¥ ì‘ì€ í–‰(ë“¤)ì„ í¬í•¨í•˜ëŠ” DataFrameì…ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "def find_smallest_in_group(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    iris DataFrameì„ í’ˆì¢…ë³„ë¡œ ê·¸ë£¹í™”í•˜ê³ , ê° ê·¸ë£¹ì—ì„œ 'petal width (cm)'ê°€\n",
        "    ê°€ì¥ ì‘ì€ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
        "\n",
        "    ë§¤ê°œë³€ìˆ˜:\n",
        "        df: 'species'ì™€ 'petal width (cm)' ì»¬ëŸ¼ì„ í¬í•¨í•˜ëŠ” iris DataFrameì…ë‹ˆë‹¤.\n",
        "\n",
        "    ë°˜í™˜ê°’:\n",
        "        ê° í’ˆì¢…ë³„ë¡œ 'petal width (cm)'ê°€ ê°€ì¥ ì‘ì€ í–‰ë“¤ë¡œ êµ¬ì„±ëœ DataFrameì…ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
        "\n",
        "smallest_per_species = find_smallest_in_group(df)\n",
        "smallest_per_species"
      ],
      "metadata": {
        "id": "Srwu-EX6Dm6J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}